{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: MNIST.traindata() is deprecated, use `MNIST(split=:train)[:]` instead.\n",
      "└ @ MLDatasets /Users/kizawamasakazu/.julia/packages/MLDatasets/mtOdX/src/datasets/vision/mnist.jl:187\n",
      "┌ Warning: MNIST.testdata() is deprecated, use `MNIST(split=:test)[:]` instead.\n",
      "└ @ MLDatasets /Users/kizawamasakazu/.julia/packages/MLDatasets/mtOdX/src/datasets/vision/mnist.jl:195\n"
     ]
    },
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `onehotbatch` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `onehotbatch` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/projects/julia-ml/work/tutorials/mnist/Flux/MLP.ipynb:12"
     ]
    }
   ],
   "source": [
    "using Flux\n",
    "using MLDatasets\n",
    "\n",
    "train_x, train_y = MNIST.traindata(Float32)\n",
    "test_x, test_y = MNIST.testdata(Float32)\n",
    "\n",
    "# 入力のベクトル化\n",
    "train_x = reshape(train_x, 28*28, :)\n",
    "test_x  = reshape(test_x, 28*28, :)\n",
    "\n",
    "# 出力のOne-hot Encoding\n",
    "train_y = onehotbatch(train_y, 0:9)\n",
    "test_y  = onehotbatch(test_y, 0:9);\n",
    "\n",
    "# データローダの準備\n",
    "train_loader = DataLoader((train_x, train_y), batchsize=16, shuffle=true)\n",
    "test_loader = DataLoader((test_x, test_y), batchsize=16, shuffle=false)\n",
    "\n",
    "model = Chain(\n",
    "    Dense(28*28, 100, relu),\n",
    "    Dense(100, 100, relu),\n",
    "    Dense(100, 50, relu),\n",
    "    Dense(50, 10),\n",
    "    softmax,\n",
    ")\n",
    "loss(x,y) = Flux.crossentropy(model(x), y)\n",
    "optimizer = Flux.ADAM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1epoch目の学習開始\n",
      "100 損失: 0.528889590281248\n",
      "200 損失: 0.41280529129207133\n",
      "300 損失: 0.3332062443003058\n",
      "400 損失: 0.3028476855017245\n",
      "500 損失: 0.34030175527483225\n",
      "600 損失: 0.28135498837903145\n",
      "700 損失: 0.2564445942506194\n",
      "800 損失: 0.22800349096246064\n",
      "900 損失: 0.24485486240871251\n",
      "1000 損失: 0.23178228713311255\n",
      "1100 損失: 0.19592455505989492\n",
      "1200 損失: 0.21540689186351375\n",
      "1300 損失: 0.22473019910044967\n",
      "1400 損失: 0.17660146478591487\n",
      "1500 損失: 0.18526390455150976\n",
      "1600 損失: 0.1776341816427186\n",
      "1700 損失: 0.1526700362802483\n",
      "1800 損失: 0.17441530130351893\n",
      "1900 損失: 0.1640099706709385\n",
      "2000 損失: 0.16270766730252653\n",
      "2100 損失: 0.1372136194191873\n",
      "2200 損失: 0.1385561321868561\n",
      "2300 損失: 0.16881504196710884\n",
      "2400 損失: 0.1427622214773437\n",
      "2500 損失: 0.17249103755299003\n",
      "2600 損失: 0.1362716656707227\n",
      "2700 損失: 0.15004097197027877\n",
      "2800 損失: 0.1378851543678902\n",
      "2900 損失: 0.15869457368287257\n",
      "3000 損失: 0.14904278972195462\n",
      "3100 損失: 0.14375870103440247\n",
      "3200 損失: 0.13404894365221262\n",
      "3300 損失: 0.13579560298905707\n",
      "3400 損失: 0.12855068596974015\n",
      "3500 損失: 0.11886882289997303\n",
      "3600 損失: 0.1276168003628962\n",
      "3700 損失: 0.13248743649944664\n",
      "1epoch目の学習終了\n",
      "2epoch目の学習開始\n",
      "100 損失: 0.12929100518361666\n",
      "200 損失: 0.11350831444677897\n",
      "300 損失: 0.1299249753920012\n",
      "400 損失: 0.132984407150466\n",
      "500 損失: 0.11460501647528727\n",
      "600 損失: 0.1177106511657592\n",
      "700 損失: 0.1326939911112655\n",
      "800 損失: 0.1491821289646905\n",
      "900 損失: 0.10894995927389245\n",
      "1000 損失: 0.11343258770212997\n",
      "1100 損失: 0.11414886244747321\n",
      "1200 損失: 0.11932629816122353\n",
      "1300 損失: 0.11877889832814689\n",
      "1400 損失: 0.12205581986001343\n",
      "1500 損失: 0.12767466975043062\n",
      "1600 損失: 0.11008216772032901\n",
      "1700 損失: 0.12347081934025045\n",
      "1800 損失: 0.14493387190536597\n",
      "1900 損失: 0.11642722093897173\n",
      "2000 損失: 0.12046098592614289\n",
      "2100 損失: 0.1261523399177473\n",
      "2200 損失: 0.11732216692899819\n",
      "2300 損失: 0.17864402115540579\n",
      "2400 損失: 0.1122882361559663\n",
      "2500 損失: 0.1239750099460245\n",
      "2600 損失: 0.13064758444132749\n",
      "2700 損失: 0.10218708248599433\n",
      "2800 損失: 0.11537283953810111\n",
      "2900 損失: 0.11021908455647063\n",
      "3000 損失: 0.09769259976017639\n",
      "3100 損失: 0.11926986593259499\n",
      "3200 損失: 0.09900297783366405\n",
      "3300 損失: 0.12322555479310103\n",
      "3400 損失: 0.11450604990318534\n",
      "3500 損失: 0.1031070365903899\n",
      "3600 損失: 0.10325537838953314\n",
      "3700 損失: 0.1081378922517877\n",
      "2epoch目の学習終了\n",
      "3epoch目の学習開始\n",
      "100 損失: 0.09350463716815575\n",
      "200 損失: 0.09415304766588961\n",
      "300 損失: 0.1078886146272649\n",
      "400 損失: 0.09017498780835012\n",
      "500 損失: 0.10305336222774931\n",
      "600 損失: 0.09230145275635877\n",
      "700 損失: 0.0985316626273794\n",
      "800 損失: 0.09010392081098398\n",
      "900 損失: 0.10622891804495593\n",
      "1000 損失: 0.10601842998547363\n",
      "1100 損失: 0.09250434722491772\n",
      "1200 損失: 0.10244227968708146\n",
      "1300 損失: 0.08515972124864929\n",
      "1400 損失: 0.09631299914048869\n",
      "1500 損失: 0.08844157172841369\n",
      "1600 損失: 0.0919754152476613\n",
      "1700 損失: 0.09389953278051107\n",
      "1800 損失: 0.09334199958813842\n",
      "1900 損失: 0.11058100136063585\n",
      "2000 損失: 0.09269782603652274\n",
      "2100 損失: 0.11011192924340721\n",
      "2200 損失: 0.08280125177764566\n",
      "2300 損失: 0.08091878998660831\n",
      "2400 損失: 0.08947642827914679\n",
      "2500 損失: 0.08485289434227161\n",
      "2600 損失: 0.08179984533158713\n",
      "2700 損失: 0.09969523864622461\n",
      "2800 損失: 0.09929788069842325\n",
      "2900 損失: 0.0929348214043217\n",
      "3000 損失: 0.12495995070897625\n",
      "3100 損失: 0.08737310391562714\n",
      "3200 損失: 0.09518095009453609\n",
      "3300 損失: 0.10436190166451852\n",
      "3400 損失: 0.10539950805404223\n",
      "3500 損失: 0.0973139970704593\n",
      "3600 損失: 0.10364722110380244\n",
      "3700 損失: 0.09508612359573598\n",
      "3epoch目の学習終了\n",
      "4epoch目の学習開始\n",
      "100 損失: 0.08140219375656452\n",
      "200 損失: 0.08819952691590952\n",
      "300 損失: 0.09032792370326934\n",
      "400 損失: 0.08420447833004291\n",
      "500 損失: 0.08010503951599239\n",
      "600 損失: 0.08836400984647917\n",
      "700 損失: 0.11683878351393796\n",
      "800 損失: 0.0802702677126974\n",
      "900 損失: 0.10295443008869479\n",
      "1000 損失: 0.08367686393935\n",
      "1100 損失: 0.09902340867030507\n",
      "1200 損失: 0.09227887869565893\n",
      "1300 損失: 0.0995065032045568\n",
      "1400 損失: 0.08641616323483904\n",
      "1500 損失: 0.09068601726572378\n",
      "1600 損失: 0.10203602323213709\n",
      "1700 損失: 0.10019479203249794\n",
      "1800 損失: 0.10922924708928913\n",
      "1900 損失: 0.08722203177794872\n",
      "2000 損失: 0.11153420858671306\n",
      "2100 損失: 0.08386665094821583\n",
      "2200 損失: 0.0964216915066383\n",
      "2300 損失: 0.11034438717454904\n",
      "2400 損失: 0.07824648109382833\n",
      "2500 損失: 0.09109806059693801\n",
      "2600 損失: 0.08839265744508303\n",
      "2700 損失: 0.10434382751028025\n",
      "2800 損失: 0.08611197646964283\n",
      "2900 損失: 0.08292898498576615\n",
      "3000 損失: 0.09435762680050466\n",
      "3100 損失: 0.0877792633846635\n",
      "3200 損失: 0.08198962449309183\n",
      "3300 損失: 0.09047529804875376\n",
      "3400 損失: 0.09540539845635648\n",
      "3500 損失: 0.0953207985412795\n",
      "3600 損失: 0.09046028284103777\n",
      "3700 損失: 0.08747283782921732\n",
      "4epoch目の学習終了\n",
      "5epoch目の学習開始\n",
      "100 損失: 0.08524828789676539\n",
      "200 損失: 0.08866376677309162\n",
      "300 損失: 0.08677694432214048\n",
      "400 損失: 0.07818542126891116\n",
      "500 損失: 0.10754608829036588\n",
      "600 損失: 0.09732753044440141\n"
     ]
    }
   ],
   "source": [
    "# エポックによる反復学習\n",
    "epochs = 100\n",
    "\n",
    "for epoch in 1:epochs\n",
    "    loss_loss = 0.0\n",
    "    println(\"$(epoch)epoch目の学習開始\")\n",
    "    for (i, train_data) in enumerate(train_loader)\n",
    "        Flux.train!(loss, Flux.params(model), [train_data], optimizer)\n",
    "        # 途中経過\n",
    "        (i % 100) == 0 && begin\n",
    "            loss_value = 0.0\n",
    "            count = 0\n",
    "            for (x,y) in test_data_loader\n",
    "                count += 1\n",
    "                loss_value += loss(x,y)\n",
    "            end\n",
    "            loss_value /= count\n",
    "        end\n",
    "    end\n",
    "    println(\"epoch=$(epoch)\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検証\n",
    "test_accuracy = 0.0\n",
    "cnt = 0\n",
    "for (i, testdata) in enumerate(testdata_loader)\n",
    "    x, y = testdata\n",
    "    outputs = model(x)\n",
    "    yhat = mapslices(argmax, outputs, dims=1)\n",
    "    y = mapslices(argmax, y, dims=1)\n",
    "    test_accuracy += sum(y .== yhat)\n",
    "    cnt += size(y,2)\n",
    "end\n",
    "test_accuracy /= cnt\n",
    "println(\"正解率: $(test_accuracy)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0-rc3",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0-rc3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
